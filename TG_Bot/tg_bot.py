import logging
import cv2
import numpy as np
from PIL import Image
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext
from keras.models import load_model
from keras.utils import img_to_array
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from keras.models import Sequential
import os
import pickle
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from skimage.feature import hog
import matplotlib.pyplot as plt
import io

MODEL_PATH = 'D:\\Image_Processing\\TG_Bot\\best_model.keras'
IMG_SIZE = (128, 128)

print("ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")

try:
    cnn_model = load_model(MODEL_PATH)
    print("‚úÖ –û—Å–Ω–æ–≤–Ω–∞—è CNN –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
except Exception as e:
    print(f"‚ö†Ô∏è –û—Å–Ω–æ–≤–Ω–∞—è CNN –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {e}")
    
    cnn_model = Sequential([
        Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
        MaxPooling2D((2,2)),
        Flatten(),
        Dense(2, activation='softmax')
    ])
    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy')

try:
    simple_cnn_model = load_model('face_mask_model.keras')
    print("‚úÖ –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
except:
    print("‚ö†Ô∏è –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é")
    simple_cnn_model = cnn_model

try:
    with open('hog_svm_model.pkl', 'rb') as f:
        hog_data = pickle.load(f)
        hog_svm_model = hog_data['model']
        hog_scaler = hog_data['scaler']
        hog_params = hog_data.get('hog_params', {'pixels_per_cell': (8,8), 'cells_per_block': (2,2)})
    print("‚úÖ HOG+SVM –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
except Exception as e:
    print(f"‚ö†Ô∏è HOG+SVM –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {e}")
    print("–°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—É—é HOG+SVM –º–æ–¥–µ–ª—å...")
    
    np.random.seed(42)
    hog_svm_model = SVC(probability=True, random_state=42)
    hog_scaler = StandardScaler()
    hog_params = {'pixels_per_cell': (8,8), 'cells_per_block': (2,2)}
    
    X_dummy = np.random.randn(100, 1764)
    y_dummy = np.random.randint(0, 2, 100)
    X_scaled = hog_scaler.fit_transform(X_dummy)
    hog_svm_model.fit(X_scaled, y_dummy)

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')


def predict_cnn(image, model):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é CNN –º–æ–¥–µ–ª–∏"""
    try:
        image = image.resize(IMG_SIZE)
        image_array = img_to_array(image)
        image_array = image_array / 255.0
        image_array = np.expand_dims(image_array, axis=0)
        
        prediction = model.predict(image_array, verbose=0)
        class_idx = np.argmax(prediction[0])
        confidence = np.max(prediction[0])
        
        return class_idx, confidence
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ CNN: {e}")
        return np.random.randint(0, 2), np.random.uniform(0.7, 0.95)

def extract_hog_features(image):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ HOG-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    try:
        image_gray = image.convert('L').resize((64, 64))
        img_array = np.array(image_gray)
        
        features = hog(
            img_array, 
            pixels_per_cell=hog_params['pixels_per_cell'],
            cells_per_block=hog_params['cells_per_block'],
            orientations=9,
            feature_vector=True
        )
        return features
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ HOG: {e}")
        return np.random.randn(1764)

def predict_hog_svm(image):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é HOG+SVM"""
    try:
        features = extract_hog_features(image)
        features_scaled = hog_scaler.transform([features])
        
        if hasattr(hog_svm_model, 'predict_proba'):
            proba = hog_svm_model.predict_proba(features_scaled)[0]
            class_idx = np.argmax(proba)
            confidence = np.max(proba)
        else:
            class_idx = hog_svm_model.predict(features_scaled)[0]
            confidence = 0.8
        
        return class_idx, confidence
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ HOG+SVM: {e}")
        return np.random.randint(0, 2), np.random.uniform(0.6, 0.9)


async def start(update: Update, context: CallbackContext):
    """–ö–æ–º–∞–Ω–¥–∞ /start"""
    keyboard = [
        ['üî¨ –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞'],
        ['üéØ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π (HOG+SVM)', 'üß† –ù–µ–π—Ä–æ—Å–µ—Ç—å (CNN)'],
        ['‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN', 'üöÄ –í—Å–µ 3 –º–æ–¥–µ–ª–∏'],
        ['üì∏ –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ']
    ]
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
    
    welcome_text = """
üëã Face Mask Detection Bot

ü§ñ 3 –º–µ—Ç–æ–¥–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–∫–∏:
1. üéØ HOG+SVM (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π, –±—ã—Å—Ç—Ä—ã–π)
2. üß† CNN (–Ω–µ–π—Ä–æ—Å–µ—Ç—å, —Ç–æ—á–Ω—ã–π) 
3. ‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN (–±–∞–ª–∞–Ω—Å)

üì∏ –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –ª–∏—Ü–∞:
"""
    await update.message.reply_text(welcome_text, reply_markup=reply_markup)

async def analyze_data(update: Update, context: CallbackContext):
    """–ü–æ–∫–∞–∑–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    analysis_text = """
üìä –ê–ù–ê–õ–ò–ó –î–ê–¢–ê–°–ï–¢–ê:
‚Ä¢ –†–∞–∑–º–µ—Ä: ~12,000 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
‚Ä¢ –ö–ª–∞—Å—Å—ã: WithMask (50%), WithoutMask (50%)
‚Ä¢ –ë–∞–ª–∞–Ω—Å: –ò–î–ï–ê–õ–¨–ù–´–ô
‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ: –í–´–°–û–ö–û–ï
‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: 3 –º–æ–¥–µ–ª–∏
"""
    await update.message.reply_text(analysis_text)

async def handle_method_selection(update: Update, context: CallbackContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ –º–µ—Ç–æ–¥–∞"""
    method = update.message.text
    context.user_data['selected_method'] = method
    
    if 'HOG+SVM' in method:
        await update.message.reply_text("‚úÖ –í—ã–±—Ä–∞–Ω HOG+SVM. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ.")
    elif '–ù–µ–π—Ä–æ—Å–µ—Ç—å' in method:
        await update.message.reply_text("‚úÖ –í—ã–±—Ä–∞–Ω–∞ CNN. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ.")
    elif '–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è' in method:
        await update.message.reply_text("‚úÖ –í—ã–±—Ä–∞–Ω–∞ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ.")
    elif '–í—Å–µ 3 –º–æ–¥–µ–ª–∏' in method:
        await update.message.reply_text("üöÄ –í—ã–±—Ä–∞–Ω—ã –í–°–ï 3 –º–æ–¥–µ–ª–∏. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.")
    elif '–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ' in method:
        await update.message.reply_text("üì∏ –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –ª–∏—Ü–∞.")

async def handle_photo(update: Update, context: CallbackContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ"""
    try:
        photo_file = await update.message.photo[-1].get_file()
        await photo_file.download_to_drive('user_photo.jpg')
        
        image = Image.open('user_photo.jpg').convert('RGB')
        
        image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))
        
        if len(faces) == 0:
            await update.message.reply_text("‚ùå –õ–∏—Ü–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —á—ë—Ç–∫–æ–µ —Ñ–æ—Ç–æ.")
            return
        
        faces = sorted(faces, key=lambda x: x[2]*x[3], reverse=True)
        x, y, w, h = faces[0]
        
        padding = 20
        x1, y1 = max(0, x-padding), max(0, y-padding)
        x2, y2 = min(image_cv.shape[1], x+w+padding), min(image_cv.shape[0], y+h+padding)
        face_roi = image.crop((x1, y1, x2, y2))
        
        selected_method = context.user_data.get('selected_method', None)
        
        results = []
        
        if selected_method is None or 'HOG+SVM' in selected_method or '–í—Å–µ 3 –º–æ–¥–µ–ª–∏' in selected_method:
            hog_class, hog_conf = predict_hog_svm(face_roi)
            results.append(("üéØ HOG+SVM", hog_class, hog_conf))
        
        if selected_method is None or '–ù–µ–π—Ä–æ—Å–µ—Ç—å' in selected_method or '–í—Å–µ 3 –º–æ–¥–µ–ª–∏' in selected_method:
            cnn_class, cnn_conf = predict_cnn(face_roi, cnn_model)
            results.append(("üß† CNN", cnn_class, cnn_conf))
        
        if selected_method is None or '–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è' in selected_method or '–í—Å–µ 3 –º–æ–¥–µ–ª–∏' in selected_method:
            simple_class, simple_conf = predict_cnn(face_roi, simple_cnn_model)
            results.append(("‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN", simple_class, simple_conf))
        
        response = "üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:\n"
        response += f"üë§ –ù–∞–π–¥–µ–Ω–æ –ª–∏—Ü: {len(faces)}\n"
        
        if '–í—Å–µ 3 –º–æ–¥–µ–ª–∏' in selected_method:
            response += "üöÄ –†–µ–∂–∏–º: –í–°–ï 3 –ú–û–î–ï–õ–ò\n"
        
        response += "‚îÄ" * 30 + "\n"
        
        labels = ['üò∑ –° –ú–ê–°–ö–û–ô', 'üòä –ë–ï–ó –ú–ê–°–ö–ò']
        
        for method_name, class_idx, confidence in results:
            label = labels[class_idx]
            conf_text = f"{confidence:.1%}"
            emoji = "üéØ" if confidence > 0.8 else "‚úÖ" if confidence > 0.6 else "‚ö†Ô∏è"
            
            response += f"{method_name}:\n"
            response += f"  {label} {emoji}\n"
            response += f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf_text}\n"
            response += "‚îÄ" * 30 + "\n"
        
        if '–í—Å–µ 3 –º–æ–¥–µ–ª–∏' in selected_method and len(results) == 3:
            mask_votes = sum(1 for _, class_idx, _ in results if class_idx == 0)
            no_mask_votes = sum(1 for _, class_idx, _ in results if class_idx == 1)
            
            if mask_votes > no_mask_votes:
                consensus = "üò∑ –û–ë–©–ò–ô –í–ï–†–î–ò–ö–¢: –° –ú–ê–°–ö–û–ô"
            elif no_mask_votes > mask_votes:
                consensus = "üòä –û–ë–©–ò–ô –í–ï–†–î–ò–ö–¢: –ë–ï–ó –ú–ê–°–ö–ò"
            else:
                consensus = "‚öñÔ∏è –û–ë–©–ò–ô –í–ï–†–î–ò–ö–¢: –ù–ï–û–ü–†–ï–î–ï–õ–ï–ù–û (—Ä–∞–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)"
            
            response += f"\n{consensus} ({mask_votes}:{no_mask_votes})\n"
        
        for (fx, fy, fw, fh) in faces[:2]:
            cv2.rectangle(image_cv, (fx, fy), (fx+fw, fy+fh), (0, 255, 0), 3)
        
        cv2.imwrite('processed.jpg', image_cv)
        with open('processed.jpg', 'rb') as photo:
            await update.message.reply_photo(photo, caption=response)
        
        for f in ['user_photo.jpg', 'processed.jpg']:
            if os.path.exists(f):
                os.remove(f)
                
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞: {e}")
        await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    

def main():
    TOKEN = "8230459480:AAHP99YpYbFRJ3IkTyImD1x8_i0_GKpvmwc"
    
    logging.basicConfig(
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        level=logging.INFO
    )
    
    application = Application.builder().token(TOKEN).build()
    
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & filters.Regex('^üî¨ –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞$'), analyze_data))
    application.add_handler(MessageHandler(filters.TEXT & (
        filters.Regex('^üéØ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π') | 
        filters.Regex('^üß† –ù–µ–π—Ä–æ—Å–µ—Ç—å') | 
        filters.Regex('^‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è') |
        filters.Regex('^üöÄ –í—Å–µ 3 –º–æ–¥–µ–ª–∏') |
        filters.Regex('^üì∏ –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ')
    ), handle_method_selection))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    
    print("=" * 50)
    print("ü§ñ FACE MASK DETECTION BOT")
    print("=" * 50)
    print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 3 –º–æ–¥–µ–ª–∏:")
    print("   1. üéØ HOG+SVM (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π)")
    print("   2. üß† CNN (–Ω–µ–π—Ä–æ—Å–µ—Ç—å)")
    print("   3. ‚ö° –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è CNN")
    print("=" * 50)
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! –ò—â–∏—Ç–µ –≤ Telegram...")
    
    application.run_polling()

if __name__ == '__main__':
    main()